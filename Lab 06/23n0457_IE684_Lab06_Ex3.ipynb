{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbfsZ1hZc0_z"
      },
      "source": [
        "#**EXERCISE-3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W43NlxAvqBQb"
      },
      "source": [
        "#Que.1\n",
        "Given the regularized problem:\n",
        "\n",
        "$\n",
        "f_{\\lambda}(x) = \\lambda \\|x\\|_2^2 + \\frac{1}{2} \\|\\mathbf{Ax} - \\mathbf{y}\\|_2^2\n",
        "$\n",
        "\n",
        "We want to express it in the form:\n",
        "\n",
        "$\n",
        "f_{\\lambda}(x) = \\sum_{i=1}^{N} f_i(x)\n",
        "$\n",
        "\n",
        "where $ f_i(x) $ represents individual loss terms.\n",
        "\n",
        "The regularization term $ \\lambda \\|x\\|_2^2 $ can be divided among $ N $ loss terms, so each $ f_i(x) $ will include $ \\frac{\\lambda}{N} \\|x\\|_2^2 $.\n",
        "\n",
        "Thus, we need to express $ f_i(x) $ as:\n",
        "\n",
        "$\n",
        "f_i(x) = \\frac{\\lambda}{N} \\|x\\|_2^2 + \\frac{1}{2} \\left( (\\mathbf{a}_i^T x - y_i)^2 \\right)\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $ \\mathbf{a}_i^T $ is the transpose of the $ i $-th row of matrix $ A $, representing the features for the $ i $-th data point.\n",
        "- $ y_i $ is the $ i $-th element of vector $ y $, representing the corresponding target value.\n",
        "- $ \\lambda $ is the regularization parameter.\n",
        "- $ N $ is the number of data points.\n",
        "\n",
        "This expression includes both the regularization term and the data loss term for each data point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPhEmhS_qE1p"
      },
      "source": [
        "#Que.2\n",
        "\n",
        "The $k^{th}$ component of the function can be written as:\n",
        "\n",
        "$$g_i(x)=∇xf_i(x)=\\frac{λ}{N}x_k+[(\\sum_{j=1}^{d}A_{ij}x_j)-y_i]A_{ik}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84UI0w_fqg5K"
      },
      "source": [
        "#Que.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Oe4VfjIpBdG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "from tabulate import tabulate\n",
        "np.random.seed(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tZJSKpo2q1Ni"
      },
      "outputs": [],
      "source": [
        "N = 200\n",
        "d = 10000\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1)\n",
        "\n",
        "A = np.random.randn(N,d)\n",
        "for  j in range(A.shape[1]):\n",
        "  A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "xorig = np.ones((d,1))\n",
        "y = np.dot(A,xorig) + eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K3uuYn2xrHul"
      },
      "outputs": [],
      "source": [
        "def evalg(x, i, lamda, d):\n",
        "  assert type(x) is np.ndarray\n",
        "  A_i = np.reshape(A[i], (d, 1))\n",
        "  return np.add(np.reshape(np.matmul(A_i, np.subtract(np.matmul(A[i], x), y[i])), (d,1)), np.multiply(lamda/N, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H1EWXSN6rNIN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [01:29<00:00, 111.50it/s]\n"
          ]
        }
      ],
      "source": [
        "x = np.zeros((d,1))\n",
        "epochs = 1e4\n",
        "t = 1\n",
        "arr = np.arange(N)\n",
        "table = [[\"Time Taken\", \"||Ax_alglab7 - y||^2\", \"||x_alglab7 - xorig||^2\"]]\n",
        "start = timeit.default_timer()\n",
        "for epoch in tqdm(range(int(epochs))):\n",
        "  np.random.shuffle(arr)\n",
        "  for i in np.nditer(arr):\n",
        "    g_x = evalg(x, i, lambda_reg, d)\n",
        "    x = np.subtract(x , (1/t)*g_x)\n",
        "    t = t+1\n",
        "    if t>1e4:\n",
        "      t = 1\n",
        "alglab7time = timeit.default_timer() - start\n",
        "x_alglab7 = x\n",
        "table.append([alglab7time, np.linalg.norm(np.subtract(np.matmul(A, x_alglab7) , y))**2, np.linalg.norm(np.subtract(x_alglab7 , xorig)**2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rp8xiMKrVdZ",
        "outputId": "7f394931-feae-4872-87d3-770c54e8bd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒══════════════╤════════════════════════╤═══════════════════════════╕\n",
            "│   Time Taken │   ||Ax_alglab7 - y||^2 │   ||x_alglab7 - xorig||^2 │\n",
            "╞══════════════╪════════════════════════╪═══════════════════════════╡\n",
            "│      89.6863 │            2.14994e-05 │                   101.695 │\n",
            "╘══════════════╧════════════════════════╧═══════════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "print(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMiVgtWYrYrG"
      },
      "source": [
        "#Que.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lCwvE0zAwRm0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:27<00:00, 35.89it/s]\n",
            "100%|██████████| 100000/100000 [20:45<00:00, 80.26it/s] \n"
          ]
        }
      ],
      "source": [
        "epoch_list = [10**3, 10**5]\n",
        "table1 = [[\"epochs\",\"Time Taken\", \"||Ax_alglab7 - y||^2\", \"||x_alglab7 - xorig||^2\"]]\n",
        "for e in epoch_list:\n",
        "  start = timeit.default_timer()\n",
        "  for epoch in tqdm(range(int(e))):\n",
        "    np.random.shuffle(arr)\n",
        "    for i in np.nditer(arr):\n",
        "      g_x = evalg(x, i, lambda_reg, d)\n",
        "      x = np.subtract(x , (1/t)*g_x)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "       t = 1\n",
        "  alglab7time = timeit.default_timer() - start\n",
        "  x_alglab7 = x\n",
        "  table1.append([e,alglab7time, np.linalg.norm(np.subtract(np.matmul(A, x_alglab7) , y))**2, np.linalg.norm(np.subtract(x_alglab7 , xorig)**2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oe55Hcu4-7nG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒══════════╤══════════════╤════════════════════════╤═══════════════════════════╕\n",
            "│   epochs │   Time Taken │   ||Ax_alglab7 - y||^2 │   ||x_alglab7 - xorig||^2 │\n",
            "╞══════════╪══════════════╪════════════════════════╪═══════════════════════════╡\n",
            "│     1000 │      27.8826 │            5.73464e-06 │                   101.695 │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│   100000 │    1245.88   │            1.92578e-05 │                   101.695 │\n",
            "╘══════════╧══════════════╧════════════════════════╧═══════════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "print(tabulate(table1, headers = 'firstrow', tablefmt = 'fancy_grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy_ttVnLWqBh"
      },
      "source": [
        "we can observe from the above table that the time taken by algorithm increses with increase in no. of epochs. and we can see that the value of norm (||Ax_alglab7 - y||^2) approaches to zero in every case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frqcL3CU6j_E"
      },
      "source": [
        "#Que.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [18:28<00:00, 90.19it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:26<00:00, 145.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:27<00:00, 145.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:22<00:00, 146.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:53<00:00, 140.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current lambda is: 0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:44<00:00, 141.95it/s]\n"
          ]
        }
      ],
      "source": [
        "epochs = 10**5\n",
        "lamda_lst = [1000, 100, 10, 1, 0, 0.1]\n",
        "table2 = [[\"lamda\",\"Time Taken\", \"||Ax_alglab7 - y||^2\", \"||x_alglab7 - xorig||^2\"]]\n",
        "for l in range(len(lamda_lst)):\n",
        "  start = timeit.default_timer()\n",
        "  lamda=lamda_lst[l]\n",
        "  print('current lambda is:',lamda)\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    np.random.shuffle(arr)\n",
        "    for i in np.nditer(arr):\n",
        "      g_x = evalg(x, i, lamda, d)\n",
        "      x = np.subtract(x , (1/t)*g_x)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "       t = 1\n",
        "  alglab7time = timeit.default_timer() - start\n",
        "  x_alglab7 = x\n",
        "  table2.append([lamda,alglab7time, np.linalg.norm(np.subtract(np.matmul(A, x_alglab7) , y))**2, np.linalg.norm(np.subtract(x_alglab7 , xorig)**2)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IQe6g3r66Wh3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [11:25<00:00, 145.93it/s]\n",
            "100%|██████████| 100000/100000 [11:30<00:00, 144.74it/s]\n"
          ]
        }
      ],
      "source": [
        "epochs = 10**5\n",
        "lamda_lst = [0.01, 0.001]\n",
        "for lamda in lamda_lst:\n",
        "  start = timeit.default_timer()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    np.random.shuffle(arr)\n",
        "    for i in np.nditer(arr):\n",
        "      g_x = evalg(x, i, lamda, d)\n",
        "      x = np.subtract(x , (1/t)*g_x)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "       t = 1\n",
        "  alglab7time = timeit.default_timer() - start\n",
        "  x_alglab7 = x\n",
        "  table2.append([lamda,alglab7time, np.linalg.norm(np.subtract(np.matmul(A, x_alglab7) , y))**2, np.linalg.norm(np.subtract(x_alglab7 , xorig)**2)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YJ83NeJp1abN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒══════════╤══════════════╤════════════════════════╤═══════════════════════════╕\n",
            "│    lamda │   Time Taken │   ||Ax_alglab7 - y||^2 │   ||x_alglab7 - xorig||^2 │\n",
            "╞══════════╪══════════════╪════════════════════════╪═══════════════════════════╡\n",
            "│ 1000     │     1108.72  │         7965.58        │                   99.8482 │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│  100     │      686.038 │         3756.67        │                   99.4431 │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│   10     │      687.551 │          553.909       │                  101.005  │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│    1     │      682.212 │           10.2718      │                  101.604  │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│    0     │      713.637 │            9.53832e-26 │                  101.695  │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│    0.1   │      704.452 │            0.20338     │                  101.686  │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│    0.01  │      685.275 │            0.000654919 │                  101.694  │\n",
            "├──────────┼──────────────┼────────────────────────┼───────────────────────────┤\n",
            "│    0.001 │      690.906 │            6.74394e-06 │                  101.695  │\n",
            "╘══════════╧══════════════╧════════════════════════╧═══════════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "print(tabulate(table2, headers = 'firstrow', tablefmt = 'fancy_grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xVk7wDZWvJu"
      },
      "source": [
        "we can see that the taken taken by algorithm is almost same for each value of lambda and we can also observe that the value of norm (||Ax_alglab7 - y||^2) decreases if we decrease the value of lamda from 1000 to 0 after that the value of norm slightly increases and then again decreases and approached to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0MvS5475bU3"
      },
      "source": [
        "#Que.6\n",
        "\n",
        "we can see in the previous exercises that our failure dimension was d=10,000 and in this exercise we saw that ALG-LAB7 works for d=10000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FhhGBfo5fz0"
      },
      "source": [
        "#Que.7\n",
        " I understand that the ALG-LAB7 method is almost similar to gradient descent because in this we are updating our x by $x=x-\\frac{1}{t}∇f_i(x)$, where $\\frac{1}{t}$ is considered as step length.\n",
        "\n",
        "This method works for higher dimensions also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcw2S0IKY3pT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
